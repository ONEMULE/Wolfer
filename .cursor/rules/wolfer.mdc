---
description: 
globs: 
alwaysApply: true
---
沃风平台 (Wofeng Platform) 开发指南

I. 沃风平台 (Wofeng Platform) 开发指南引言
    A. 平台愿景与目标
    B. 集成功能概述
    C. 目标用户与使用场景
    D. 文档范围与结构

II. 整体系统架构与技术框架
    A. 拟议架构设计
    B. 组件间数据流与通信策略
    C. 技术栈推荐
        (Existing Table 5: 推荐技术栈 - I will add Anthropic SDK here)

III. 功能模块：WRF Namelist配置与生成
    A. 参数输入用户界面规范
    B. Namelist文件生成逻辑详解
    C. 校验规则与错误处理
    D. Namelist文件格式与下载机制
    E. 表1: WRF Namelist配置参数（示例节选）

IV. 功能模块：WRF模拟结果分析与风资源可视化
    A. WRF输出文件上传与校验流程
    B. 自动化风资源分析脚本规范
    C. 风资源评估关键绩效指标 (KPIs)
    D. 表2: 风资源分析KPIs与可视化指标 (示例)
    E. 交互式风资源可视化设计与需求

V. 功能模块：ABaCAS集成进行余热与经济分析
    A. ABaCAS源码集成策略
    B. WRF模拟输出到ABaCAS输入的映射实现
    C. 表3: ABaCAS输入数据映射自WRF输出 (示例)
    D. 自动化余热分析工作流与关键指标
    E. 自动化经济分析工作流与关键指标
    F. 表4: ABaCAS分析输出指标 (余热与经济) (示例)
    G. ABaCAS集成结果可视化设计与需求

VI. 用户体验 (UX) 与工作流设计
    A. 核心平台功能的用户端到端旅程图
    B. 关键UI设计原则与可用性指南
    C. 仪表盘与项目管理功能

VII. 数据管理、安全与部署考量
    A. 用户数据、WRF文件及分析结果的存储与管理策略
    B. 安全措施与访问控制
    C. 高层部署考量

VIII. 开发阶段划分与未来可扩展性
    A. 推荐的阶段性开发方案 (MVP优先)
    B. 未来功能增强与平台可扩展性考量
        (Existing text: 引入机器学习 (ML) / 人工智能 (AI) - this new section will be a concrete implementation)

**IX. 功能模块：智能交互与分析助手 (Claude 3.7 集成)**
    **引言**
        大型语言模型 (LLM) 如 Anthropic 的 Claude 3.7，为沃风平台提供了增强用户交互、辅助复杂参数配置理解、解读分析结果以及自动化部分报告生成等多种可能性。本章节详细阐述如何将 Claude 3.7 API 集成到沃风平台的 React Web 应用中。我们将采用安全的后端代理架构（Node.js）来处理与 Claude API 的通信，确保 API 密钥安全并有效管理流式响应。

    **架构概览**
        系统架构包含三个核心组件：
        1.  **React 前端应用 (沃风平台界面)**：用户交互界面，发送用户输入（如问题、配置请求）并展示 LLM 的响应。
        2.  **Node.js (Express.js) 后端代理**：作为前端和 Claude API 之间的中间层。接收前端请求，安全附加 API 密钥，转发请求给 Claude API，并处理（特别是流式）响应。
        3.  **Anthropic Claude API**：提供核心 LLM 功能。
        数据流：用户输入从 React 应用发送到 Node.js 代理。代理调用 Claude API。Claude API 生成响应，通过代理以流式方式传回 React 应用，在用户界面上实时显示。

    **A. 基础：为 LLM 集成做好准备**
        1.  **开发环境先决条件**
            *   Node.js 和 npm/yarn (推荐 v18+)
            *   沃风平台的 React 应用基础
            *   React 函数式组件和 Hooks 知识
            *   代码编辑器 (如 VS Code)
            *   版本控制 (Git)
        2.  **Anthropic 账户及 Claude 3.7 API 密钥设置**
            *   **获取 Claude 3.7 API 密钥**：
                *   访问 Anthropic 官方网站的开发者控制台。
                *   注册或登录您的 Anthropic 账户。
                *   在控制台中创建或选择一个项目，并生成 API 密钥。务必安全存储此密钥，不要硬编码到客户端。
            *   **理解 Claude 3.7 模型**：
                *   **功能**：Claude 3.7 (假设模型系列，具体如 Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku) 是 Anthropic 的先进模型系列，以其强大的推理能力、多语言处理和上下文理解著称。不同子模型在性能、速度和成本上有所权衡。本指南以 Claude 3.7 Sonnet (示例模型 `claude-3-sonnet-20240229`) 作为参考。
                *   **定价**：查阅 Anthropic 官方最新的 Claude 模型定价页面，了解输入和输出 token 的成本。例如 (仅为示例，请查阅官方文档)：
                    *   Claude 3 Sonnet: 输入 $3/百万token, 输出 $15/百万token。
                *   **速率限制**：了解所选模型和账户类型的速率限制（如每分钟请求数、每分钟token数）。超出限制将导致 API 返回错误 (通常是 HTTP 429)。
                *   **上下文窗口**：Claude 3 模型拥有较大的上下文窗口（例如 200K token），这对于处理复杂的分析任务和长对话历史非常有利。
            *   **重要提示：Claude API 的数据隐私**：
                *   仔细阅读 Anthropic 的数据使用政策。通常，通过 API 发送的数据不会被用于训练 Anthropic 的通用模型，除非用户明确选择加入此类计划。
                *   对于沃风平台处理的潜在敏感科研或商业数据，确保所选的 API 使用条款符合平台的隐私和安全要求。
            *   **表6: Claude 3.7 API：开发者关键信息 (示例)**
                | 特性             | Claude 3 Sonnet (示例) 详情 | 相关参考资料        |
                | ---------------- | --------------------------- | ------------------- |
                | 模型名称 (示例)  | `claude-3-sonnet-20240229`  | Anthropic 文档      |
                | 输入定价 (示例)  | ~$3 / 百万 token            | Anthropic 定价页面  |
                | 输出定价 (示例)  | ~$15 / 百万 token           | Anthropic 定价页面  |
                | 主要速率限制     | (根据账户类型和模型)        | Anthropic 文档      |
                | 上下文窗口 (示例)| 200K tokens                 | Anthropic 文档      |
                | 数据用于模型改进 | 默认否 (需查阅最新政策)     | Anthropic 数据政策  |
                | 流式传输支持     | 是                          | Anthropic SDK 文档  |

    **B. 构建安全的 Node.js 后端代理 (使用 Express.js)**
        1.  **初始化 Node.js 项目及核心依赖**
            *   `express`: 构建 Web 服务器。
            *   `@anthropic-ai/sdk`: Anthropic 官方 Node.js SDK。
            *   `dotenv`: 管理环境变量。
            *   `cors`: 处理跨域资源共享。
            *   *package.json 示例*
                ```json
                {
                  "dependencies": {
                    "@anthropic-ai/sdk": "^0.20.0", // 示例版本，请使用最新
                    "cors": "^2.8.5",
                    "dotenv": "^16.0.3",
                    "express": "^4.18.2"
                  }
                }
                ```
        2.  **API 密钥安全：.env 文件的角色**
            *   创建 `.env` 文件：`ANTHROPIC_API_KEY=YOUR_CLAUDE_API_KEY`
            *   在 `server.js` 中加载：`require('dotenv').config();`
            *   将 `.env` 添加到 `.gitignore`。
        3.  **构建聊天代理端点 (例如 `/api/claude-chat`)**
            ```javascript
            // server.js
            const express = require('express');
            const cors = require('cors');
            const Anthropic = require('@anthropic-ai/sdk');
            require('dotenv').config();

            const app = express();
            const port = process.env.PORT || 3001;

            app.use(cors());
            app.use(express.json());

            const anthropic = new Anthropic({
              apiKey: process.env.ANTHROPIC_API_KEY,
            });

            // POST 端点，用于处理聊天请求并启动流式响应
            app.post('/api/claude-chat', async (req, res) => {
              try {
                const { prompt, history } = req.body; // history: [{role: 'user'|'assistant', content: '...'}

                if (!prompt) {
                  return res.status(400).json({ error: "Prompt is required" });
                }

                const messages = [];
                if (history && Array.isArray(history)) {
                  messages.push(...history);
                }
                messages.push({ role: 'user', content: prompt });

                res.setHeader('Content-Type', 'text/event-stream');
                res.setHeader('Cache-Control', 'no-cache');
                res.setHeader('Connection', 'keep-alive');
                res.flushHeaders(); // 立即发送头部信息

                const stream = await anthropic.messages.stream({
                  model: 'claude-3-sonnet-20240229', // 使用具体的 Claude 模型
                  max_tokens: 2048, // 根据需要调整
                  messages: messages,
                  // system: "You are a helpful assistant for the Wofeng Platform, specializing in WRF and ABaCAS.", // 可选的系统提示
                });

                for await (const event of stream) {
                  if (event.type === 'content_block_delta' && event.delta && event.delta.type === 'text_delta') {
                    const textChunk = event.delta.text;
                    if (textChunk) {
                      res.write(`data: ${JSON.stringify({ textChunk })}\n\n`);
                    }
                  } else if (event.type === 'message_stop') {
                    res.write(`data: ${JSON.stringify({ isComplete: true })}\n\n`);
                    res.end();
                    return;
                  }
                }
              } catch (error) {
                console.error('Claude API 调用失败:', error);
                if (!res.headersSent) {
                  res.status(500).json({ error: '与AI助手通信失败' });
                } else {
                  try {
                    res.write(`event: error\ndata: ${JSON.stringify({ message: 'AI助手处理时发生错误' })}\n\n`);
                  } catch (sseError) {
                    console.error('发送SSE错误事件失败:', sseError);
                  }
                  res.end();
                }
              }
            });
            
            app.listen(port, () => {
              console.log(`代理服务器运行在 http://localhost:${port}`);
            });
            ```
            *   **注意**：上述代码使用了 Anthropic Messages API 的流式处理。`history` 的格式应为 `[{role: 'user', content: '...'}, {role: 'assistant', content: '...'}]`。

    **C. 将 LLM 融入您的 React 应用 (沃风平台前端)**
        1.  **React 聊天应用结构**
            *   在沃风平台前端项目中，可以创建一个 `src/features/claudeAssistant/` 目录。
            *   `components/`: `AssistantWindow.jsx`, `MessageList.jsx`, `MessageInput.jsx`, `MessageBubble.jsx`。
            *   `hooks/`: `useClaudeStream.js`。
            *   `services/`: `claudeApi.js`。
            *   `state/`: `claudeChatStore.js` (使用 Zustand)。
        2.  **核心 React 聊天 UI 组件**
            *   (组件结构与 Gemini 示例类似，仅需调整数据和服务调用)
        3.  **聊天状态管理 (Zustand)**
            *   `claudeChatStore.js` 结构与 Gemini 示例类似，管理 `messages`, `isLoading`, `error`。
        4.  **前后端通信 (EventSource)**
            *   `claudeApi.js`: 包含 `initiateClaudeChatStream` 函数，向 `/api/claude-chat` 发送 POST 请求。
            *   `useClaudeStream.js`: 使用 `EventSource` 连接到代理的 SSE 端点。
                *   **重要调整**：为简化，这里假设 `POST /api/claude-chat` 直接返回 SSE 流。前端将使用 `fetch` API 并手动解析 `ReadableStream` 中的 SSE 数据，或者调整后端为传统的 POST 启动 + GET 流式会话模式。为与前述 Node.js 代码一致 (POST直接流式)，前端需要用 `fetch` 处理流：
                ```javascript
                // src/features/claudeAssistant/services/claudeApi.js (部分)
                export const initiateClaudeChatStream = async (prompt, history, storeActions) => {
                  // ... (optimistic updates, set loading) ...
                  const modelMessageId = `claude-${Date.now()}`;
                  storeActions.addMessage({ /* ... model placeholder ... */});
                
                  try {
                    const response = await fetch('/api/claude-chat', {
                      method: 'POST',
                      headers: { 'Content-Type': 'application/json' },
                      body: JSON.stringify({ prompt, history }),
                    });
                
                    if (!response.ok || !response.body) { /* ... error handling ... */ }
                
                    const reader = response.body.getReader();
                    const decoder = new TextDecoder();
                
                    while (true) {
                      const { value, done } = await reader.read();
                      if (done) {
                        storeActions.finalizeLastMessage();
                        break;
                      }
                      const chunk = decoder.decode(value);
                      // SSE 消息通常以 "data: " 开头，以 "\n\n" 结尾
                      // 需要更复杂的解析逻辑来处理多个SSE事件在一个chunk或跨chunk的情况
                      const sseMessages = chunk.split('\n\n');
                      sseMessages.forEach(msgStr => {
                        if (msgStr.startsWith('data: ')) {
                          try {
                            const jsonData = msgStr.substring(5);
                            const parsedData = JSON.parse(jsonData);
                            if (parsedData.textChunk) {
                              storeActions.updateLastMessageChunk(parsedData.textChunk);
                            }
                            if (parsedData.isComplete) {
                              storeActions.finalizeLastMessage();
                              // reader.cancel(); // 可以考虑取消读取
                            }
                          } catch (e) { console.error("Error parsing SSE data:", e, "Raw:", msgStr); }
                        } else if (msgStr.startsWith('event: error')) {
                           // ... handle custom error event ...
                        }
                      });
                    }
                    storeActions.setLoading(false);
                  } catch (error) { /* ... error handling ... */ }
                };
                ```
        5.  **渲染 LLM 生成的内容**
            *   使用 `react-markdown` 和 `react-syntax-highlighter` (与 Gemini 示例相同)。
        6.  **客户端错误处理和用户反馈**
            *   (与 Gemini 示例相同原则)。

    **D. 完善和优化聊天应用 (在沃风平台上下文中)**
        1.  **聊天界面的可访问性 (a11y)**
        2.  **React 性能优化策略** (列表虚拟化对长对话尤其重要)
        3.  **样式方案** (与沃风平台整体风格一致)
        4.  **持久化聊天记录 (客户端)** (使用 Zustand persist 中间件)

    **E. 部署策略 (针对沃风平台)**
        *   (与 Gemini 示例相同原则，考虑沃风平台的整体部署方案)。

    **F. 沃风平台中 Claude 3.7 助手的具体应用场景**
        1.  **WRF Namelist 参数辅助配置**：
            *   用户提问：“`mp_physics` 参数的选项 8 代表什么？”
            *   Claude 助手：“选项 8 通常代表 Thompson 微物理方案，它是一个较复杂的方案，包含冰、雪、霰等多种水凝物的预报。适用于需要精细云物理过程模拟的场景。您希望了解更多关于它的信息或与其他方案的对比吗？”
            *   用户提问：“我的模拟区域在山区，应该如何设置 `sf_surface_physics`？”
            *   Claude 助手：“对于山区，地表过程对模拟影响显著。推荐考虑如 Noah LSM (选项 2) 或 RUC LSM (选项 4) 等包含更复杂植被和土壤模型的方案。您能提供更多关于您研究重点的信息吗？例如是否关注地表能量平衡或积雪？”
        2.  **WRF/ABaCAS 模拟结果解读与问答**：
            *   用户上传 WRF 结果后，提问：“这张100米平均风速图显示我的目标区域A风速较低，原因可能是什么？”
            *   Claude 助手 (在获得图表信息或关键KPI后)：“区域A风速较低可能与几个因素有关：1. 地形影响：如果A点位于山谷或大型障碍物背风坡，可能出现风影区。2. 局地环流：特定时间可能存在不利于强风的局地环流。3. 模拟偏差：请检查Namelist中地形数据分辨率、边界层方案是否合适。需要结合风玫瑰图和周边格点风速综合判断。”
            *   用户查看 ABaCAS 经济分析后提问：“NPV 为负值意味着什么？”
            *   Claude 助手：“NPV (净现值) 为负表示在当前设定的贴现率、投资成本、电价等经济参数下，项目的预期收益无法覆盖其全生命周期的成本，项目在经济上可能不可行。您可以尝试调整输入参数（如降低成本、寻找更高电价）进行敏感性分析，看看NPV如何变化。”
        3.  **辅助报告生成**：
            *   用户选择一组分析结果和图表，请求：“帮我生成关于项目X风资源评估的初步摘要。”
            *   Claude 助手：“项目X位于[地理位置]，根据WRF模拟结果（模拟时段[日期]），主要结论如下：100米高度年平均风速为[X]m/s，主导风向为[方向]，平均风功率密度为[Y]W/m²。Weibull分布参数 k=[k值], A=[A值]。[其他关键发现]... 请注意，这仅为初步评估，详细报告需进一步分析。”
        4.  **平台使用与技术支持问答**：
            *   用户提问：“如何在平台上对比两次不同 WRF 配置的模拟结果？”
            *   Claude 助手：“您可以通过以下步骤对比分析结果：1. 确保两次分析都已完成并在您的项目中。2. 进入项目详情页，选择‘对比分析’功能。3. 选择您希望对比的两次WRF分析运行。平台将并排展示关键KPI和可视化图表以便比较。”
        5.  **代码/脚本理解与生成辅助 (高级)**：
            *   用户提供一段用于WRF后处理的Python脚本片段，提问：“这段脚本中 `wrf.getvar(ncfile, 'slp')` 是做什么的？”
            *   Claude 助手：“`wrf.getvar(ncfile, 'slp')` 是 `wrf-python` 库中的一个函数，用于从WRF输出文件 (ncfile) 中提取并计算海平面气压 (Sea Level Pressure, 'slp') 变量。”

    **G. 结论与未来展望 (针对 Claude 3.7 集成)**
        将 Claude 3.7 集成到沃风平台，可以显著提升平台的智能化水平和用户友好度。通过 Node.js 代理保障安全通信，利用 React 和 Zustand 构建交互界面，能够为用户提供强大的自然语言交互能力。未来的扩展可以包括更深度的上下文感知、与平台工作流更紧密的集成（如根据用户操作主动提供建议）、以及利用 Claude 的多模态能力（如果适用）。

IX. 结论与建议 (沃风平台总体结论，现在是第X节)
    (Original content of section IX)
